{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a94453a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2,f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4592825",
   "metadata": {},
   "source": [
    "Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "455551a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_applications = pd.read_csv('loan_applications.csv')\n",
    "credit_features = pd.read_csv('credit_features_subset.csv')\n",
    "data_dictionary = pd.read_csv('loan_data_dictionary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88fe567",
   "metadata": {},
   "source": [
    "Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1368894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loan_applications.info())\n",
    "print(credit_features.info())\n",
    "print(data_dictionary.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60fccce",
   "metadata": {},
   "source": [
    "Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc320e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(loan_applications, credit_features, on='UID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a379f9e",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a9ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -1 with NaN for relevant columns\n",
    "columns_to_replace = [\n",
    "    'ALL_AgeOfOldestAccount', 'ALL_AgeOfYoungestAccount', 'ALL_CountActive',\n",
    "    'ALL_CountClosedLast12Months', 'ALL_CountDefaultAccounts',\n",
    "    'ALL_CountOpenedLast12Months', 'ALL_CountSettled', 'ALL_MeanAccountAge',\n",
    "    'ALL_SumCurrentOutstandingBal', 'ALL_SumCurrentOutstandingBalExcMtg',\n",
    "    'ALL_WorstPaymentStatusActiveAccounts'\n",
    "]\n",
    "\n",
    "for col in columns_to_replace:\n",
    "    merged_data[col] = merged_data[col].replace(-1, np.nan)\n",
    "\n",
    "print(\"Negative values replaced with NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify outliers using IQR method\n",
    "def identify_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "# Check for outliers in numeric columns\n",
    "numeric_columns = merged_data.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_columns:\n",
    "    outliers = identify_outliers(merged_data, col)\n",
    "    if not outliers.empty:\n",
    "        print(f\"Outliers in {col}: {len(outliers)} ({len(outliers)/len(merged_data)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ddb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers(df, column, lower_percentile=0.01, upper_percentile=0.99):\n",
    "    lower = df[column].quantile(lower_percentile)\n",
    "    upper = df[column].quantile(upper_percentile)\n",
    "    df[column] = df[column].clip(lower, upper)\n",
    "    return df\n",
    "\n",
    "# Cap outliers for most variables\n",
    "columns_to_cap = [\n",
    "    'ALL_AgeOfOldestAccount', 'ALL_AgeOfYoungestAccount', 'ALL_Count',\n",
    "    'ALL_CountActive', 'ALL_CountClosedLast12Months', 'ALL_CountDefaultAccounts',\n",
    "    'ALL_CountOpenedLast12Months', 'ALL_CountSettled', 'ALL_MeanAccountAge'\n",
    "]\n",
    "\n",
    "for col in columns_to_cap:\n",
    "    merged_data = cap_outliers(merged_data, col)\n",
    "\n",
    "# Log transform highly skewed variables\n",
    "columns_to_log = ['ALL_SumCurrentOutstandingBal', 'ALL_SumCurrentOutstandingBalExcMtg']\n",
    "\n",
    "for col in columns_to_log:\n",
    "    merged_data[f'{col}_Log'] = np.log1p(merged_data[col])\n",
    "    \n",
    "print(\"Outliers handled through capping and log transformation\")\n",
    "\n",
    "# Check the results\n",
    "for col in columns_to_cap + columns_to_log:\n",
    "    print(f\"\\nSummary for {col}:\")\n",
    "    print(merged_data[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = merged_data.isnull().sum()\n",
    "print(\"\\nMissing values:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# For this step, we'll just impute missing values with median\n",
    "for col in merged_data.columns:\n",
    "    if merged_data[col].isnull().sum() > 0:\n",
    "        if merged_data[col].dtype != 'object':  # Only for numeric columns\n",
    "            merged_data[col].fillna(merged_data[col].median(), inplace=True)\n",
    "\n",
    "print(\"\\nMissing values imputed with median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For most fields, we'll use median imputation\n",
    "columns_for_median_imputation = [\n",
    "    'ALL_AgeOfOldestAccount', 'ALL_AgeOfYoungestAccount', \n",
    "    'ALL_CountClosedLast12Months', 'ALL_CountOpenedLast12Months',\n",
    "    'ALL_CountSettled', 'ALL_MeanAccountAge',\n",
    "    'ALL_SumCurrentOutstandingBal', 'ALL_SumCurrentOutstandingBalExcMtg'\n",
    "]\n",
    "\n",
    "for col in columns_for_median_imputation:\n",
    "    median_value = merged_data[col].median()\n",
    "    merged_data[col].fillna(median_value, inplace=True)\n",
    "\n",
    "# For count and status fields, we'll use 0 or a special value\n",
    "merged_data['ALL_CountActive'].fillna(0, inplace=True)\n",
    "merged_data['ALL_CountDefaultAccounts'].fillna(0, inplace=True)\n",
    "merged_data['ALL_WorstPaymentStatusActiveAccounts'].fillna(-1, inplace=True)  # -1 can indicate 'unknown' status\n",
    "\n",
    "print(\"Missing values handled\")\n",
    "# Verify that all missing values have been addressed\n",
    "missing_after = merged_data.isnull().sum()\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(missing_after[missing_after > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e308d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ApplicationDate to datetime if not already\n",
    "merged_data['ApplicationDate'] = pd.to_datetime(\n",
    "    merged_data['ApplicationDate'], \n",
    "    format='%d/%m/%Y',  \n",
    "    errors='coerce'     \n",
    ")\n",
    "\n",
    "# Create new features from ApplicationDate\n",
    "merged_data['ApplicationYear'] = merged_data['ApplicationDate'].dt.year\n",
    "merged_data['ApplicationMonth'] = merged_data['ApplicationDate'].dt.month\n",
    "merged_data['ApplicationDayOfWeek'] = merged_data['ApplicationDate'].dt.dayofweek\n",
    "\n",
    "print(\"DateTime features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['ALL_TimeSinceMostRecentDefault'].replace(-1, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f795fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values after handling special cases:\")\n",
    "print(merged_data.isnull().sum()[merged_data.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb8cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02646b",
   "metadata": {},
   "source": [
    "Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract features, handling potential NaT values\n",
    "merged_data['ApplicationYear'] = merged_data['ApplicationDate'].dt.year\n",
    "merged_data['ApplicationMonth'] = merged_data['ApplicationDate'].dt.month\n",
    "merged_data['ApplicationDayOfWeek'] = merged_data['ApplicationDate'].dt.dayofweek\n",
    "\n",
    "# Fill NaN values in the new columns with a suitable value, e.g., median\n",
    "merged_data['ApplicationYear'] = merged_data['ApplicationYear'].fillna(merged_data['ApplicationYear'].median())\n",
    "merged_data['ApplicationMonth'] = merged_data['ApplicationMonth'].fillna(merged_data['ApplicationMonth'].median())\n",
    "merged_data['ApplicationDayOfWeek'] = merged_data['ApplicationDayOfWeek'].fillna(merged_data['ApplicationDayOfWeek'].median())\n",
    "\n",
    "# Continue with the rest of your feature engineering\n",
    "# Create a debt-to-income ratio \n",
    "if 'Income' in merged_data.columns:\n",
    "    merged_data['DebtToIncomeRatio'] = merged_data['Amount'] / merged_data['Income']\n",
    "\n",
    "# Create a feature for total number of accounts\n",
    "merged_data['TotalAccounts'] = merged_data['ALL_Count']\n",
    "\n",
    "# Create a feature for proportion of active accounts\n",
    "merged_data['ProportionActiveAccounts'] = merged_data['ALL_CountActive'] / merged_data['ALL_Count']\n",
    "\n",
    "# Create a feature for recent account activity\n",
    "merged_data['RecentAccountActivity'] = merged_data['ALL_CountOpenedLast12Months'] - merged_data['ALL_CountClosedLast12Months']\n",
    "\n",
    "# Log transform for skewed numeric features (example with 'Amount')\n",
    "merged_data['LogAmount'] = np.log1p(merged_data['Amount'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are constant or entirely NaN\n",
    "columns_to_drop = ['ALL_TimeSinceMostRecentDefault', 'ApplicationYear']\n",
    "merged_data = merged_data.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Dropped columns: {columns_to_drop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace inf values with NaN\n",
    "merged_data['ProportionActiveAccounts'] = merged_data['ProportionActiveAccounts'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Fill NaN values with the median (or another meaningful value)\n",
    "merged_data['ProportionActiveAccounts'].fillna(merged_data['ProportionActiveAccounts'].median(), inplace=True)\n",
    "\n",
    "print(\"Handled inf values in ProportionActiveAccounts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11feb5c3",
   "metadata": {},
   "source": [
    "Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ba1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns\n",
    "numeric_columns = merged_data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = merged_data[numeric_columns].corr()\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Numeric Features')\n",
    "plt.show()\n",
    "\n",
    "# Print correlations with the target variable (assuming 'Success' is the target)\n",
    "target_correlations = correlation_matrix['Success'].sort_values(ascending=False)\n",
    "print(\"Top correlations with Success:\")\n",
    "print(target_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8cec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features based on correlation analysis\n",
    "selected_features = [\n",
    "    'ALL_MeanAccountAge', 'ALL_AgeOfOldestAccount', \n",
    "    'ALL_SumCurrentOutstandingBal_Log', 'Amount',\n",
    "    'ALL_WorstPaymentStatusActiveAccounts', 'Term',\n",
    "    # Add other features based on your analysis\n",
    "]\n",
    "# Prepare data\n",
    "X = merged_data[selected_features]\n",
    "y = merged_data['Success']\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320aa0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e106bea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
